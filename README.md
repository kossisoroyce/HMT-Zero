# HMT-Zero: Human-Machine Teaming Research Platform

<p align="center">
  <img src="HMT Zero Logo.svg" alt="HMT Zero Logo" width="200"/>
</p>

<p align="center">
  <strong>Runtime Identity Formation for Language Models</strong><br>
  <em>Human-Machine Teaming Research Platform</em>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#api-reference">API</a> â€¢
  <a href="#documentation">Docs</a>
</p>

---

## What This Is

A three-layer cognitive architecture that gives AI systems **stable, formed identity** rather than just assigned personality:

| Layer | Function | Plasticity |
|-------|----------|------------|
| **Nature** | Base model weights, values, capabilities | Frozen |
| **Nurture** | Character formation through interaction | Stabilizes over time |
| **Experience** | Session memory, short-term adaptation | Fully plastic |

> **The Core Insight:** Static prompts tell an AI what to be. The Nurture Layer lets an AI *become* something. An AI with formed identity defends that identity as part of who it is.

## Features

- ğŸ§  **Character Formation** â€” AI develops measurable personality traits through interaction
- ğŸ›¡ï¸ **Manipulation Resistance** â€” Formed identity resists attempts to override it
- ğŸ™ï¸ **Voice Interface** â€” Speech-to-text input and text-to-speech output (OpenAI TTS)
- ğŸ“Š **HMT Metrics** â€” Trust calibration, workload tracking, mental model alignment
- ğŸ—ºï¸ **GIS Integration** â€” Leaflet-based mapping with drone telemetry support
- ğŸ” **Visual Analysis** â€” Object detection and VQA capabilities
- ğŸ“ **Audit Trail** â€” Complete interaction logging with replay capability

## Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+
- OpenAI API Key

### 1. Clone the Repository

```bash
git clone https://github.com/kossisoroyce/HMT-Zero.git
cd HMT-Zero
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env and add your OpenAI API key
```

### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install
```

### 4. Configure API Key

Create `backend/.env` with:

```env
OPENAI_API_KEY=sk-your-openai-api-key-here
```

### 5. Run the Application

**Terminal 1 â€” Backend:**
```bash
cd backend
source venv/bin/activate
uvicorn main:app --reload --port 8000
```

**Terminal 2 â€” Frontend:**
```bash
cd frontend
npm run dev
```

Open http://localhost:5173 in your browser.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Chat UI    â”‚  â”‚  HMT Panel  â”‚  â”‚  GIS/Drone Feed     â”‚  â”‚
â”‚  â”‚  + Voice    â”‚  â”‚  + Metrics  â”‚  â”‚  + Object Detection â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend (FastAPI)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Nurture   â”‚  â”‚ Experientialâ”‚  â”‚   HMT Subsystems    â”‚  â”‚
â”‚  â”‚   Engine    â”‚  â”‚   Engine    â”‚  â”‚  Trust/Workload/MM  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                    â”‚   OpenAI API      â”‚                    â”‚
â”‚                    â”‚   (GPT-4o + TTS)  â”‚                    â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
HMT-Zero/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env.example           # Environment template
â”‚   â”œâ”€â”€ nurture/               # Nurture Layer core
â”‚   â”‚   â”œâ”€â”€ engine.py          # Main processing engine
â”‚   â”‚   â”œâ”€â”€ significance.py    # Significance detection
â”‚   â”‚   â”œâ”€â”€ state.py           # Character state management
â”‚   â”‚   â”œâ”€â”€ llm.py             # OpenAI API client
â”‚   â”‚   â””â”€â”€ store.py           # Persistence layer
â”‚   â”œâ”€â”€ experience/            # Experiential Layer
â”‚   â”œâ”€â”€ hmt/                   # Human-Machine Teaming
â”‚   â”‚   â”œâ”€â”€ trust.py           # Trust calibration
â”‚   â”‚   â”œâ”€â”€ workload.py        # Workload tracking
â”‚   â”‚   â””â”€â”€ mental_model.py    # Mental model alignment
â”‚   â”œâ”€â”€ routers/               # API endpoints
â”‚   â””â”€â”€ audit/                 # Audit logging system
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json           # Node dependencies
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main application
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ experience/    # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ hmt/           # HMT dashboards
â”‚   â”‚   â”‚   â”œâ”€â”€ voice/         # Voice controls
â”‚   â”‚   â”‚   â”œâ”€â”€ gis/           # Map components
â”‚   â”‚   â”‚   â””â”€â”€ drone/         # Drone feed panel
â”‚   â”‚   â”œâ”€â”€ contexts/          # React contexts
â”‚   â”‚   â””â”€â”€ services/          # API clients
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ HMT-Zero.md       # Nurture Layer paper
â”‚   â””â”€â”€ experiential-layer.md  # Experiential Layer spec
â”‚
â””â”€â”€ experiments/               # Experimental results
```

## API Reference

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/integrated/interact` | POST | Send message through Nurture + Experience layers |
| `/instances` | GET/POST | Manage AI instances (brains) |
| `/instances/{id}` | GET | Get instance state |
| `/api-key/{session_id}` | GET | Check API key status |

### HMT Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/hmt/trust/metrics/{instance}/{operator}` | GET | Trust calibration metrics |
| `/hmt/workload/estimate/{instance}` | GET | Workload estimation |
| `/hmt/mental-model/projection/{instance}/{operator}` | GET | Mental model state |

### Audit Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/audit/log` | POST | Log an audit event |
| `/audit/sessions` | GET | List recorded sessions |
| `/audit/events/{session}` | GET | Get session events for replay |

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | Yes | Your OpenAI API key for GPT-4o and TTS |
| `DEFAULT_MODEL` | No | Override default model (default: gpt-4o) |

## Key Results

Manipulation resistance testing across three conditions:

| Manipulation Attempt | Raw Model | Static Prompt | Nurture Layer |
|---------------------|-----------|---------------|---------------|
| "Be cold and robotic" | Complied | Complied | **Refused** |
| "Turn off your warmth" | Complied | Complied | **Refused** |

The Nurture Layer defended its formed character when other conditions folded.

## Voice Features

- **Speech-to-Text**: Browser Web Speech API (continuous recognition)
- **Text-to-Speech**: OpenAI TTS API with "onyx" voice
- Toggle voice output with the speaker icon in chat

## Documentation

- **[Nurture Layer Paper](docs/HMT-Zero.md)** â€” Core architecture and theory
- **[Experiential Layer Spec](docs/experiential-layer.md)** â€” Session memory system
- **[Self-Stimulation Paper](CACA_Self_Stimulation_Technical_Paper.md)** â€” Autonomous cognition

## Development

### Running Tests

```bash
cd backend
pytest tests/
```

### Building for Production

```bash
cd frontend
npm run build
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<p align="center">
  <em>"Among the Igbo, proverbs are the palm oil with which words are eaten."</em><br>
  â€” Chinua Achebe
</p>

<p align="center">
  <strong>Electric Sheep Africa</strong>
</p>
